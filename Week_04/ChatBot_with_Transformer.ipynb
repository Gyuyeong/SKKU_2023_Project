{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144fedcc",
   "metadata": {},
   "source": [
    "## 1. Transformer 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80d57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24f32cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):  # position과 d_model 모두 정수 값으로 주어진다\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    # sine과 cosine에 들어가는 각도를 계산하는 메소드\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # position과 d_model을 1차원 벡터화한다.\n",
    "        # position shape = (position, 1)\n",
    "        # i shape = (1, d_model)\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2]) # 0::2 => 0부터 2칸씩 => 짝수\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2]) # 1::2 => 1부터 2칸씩 => 홀수\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    # 원래 embedded vector들이 담긴 input에 positional encoding 행렬을 더해준다\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbb05a",
   "metadata": {},
   "source": [
    "### 코드 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51285e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 1), dtype=float32, numpy=\n",
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [17.],\n",
       "       [18.],\n",
       "       [19.],\n",
       "       [20.],\n",
       "       [21.],\n",
       "       [22.],\n",
       "       [23.],\n",
       "       [24.],\n",
       "       [25.],\n",
       "       [26.],\n",
       "       [27.],\n",
       "       [28.],\n",
       "       [29.],\n",
       "       [30.],\n",
       "       [31.],\n",
       "       [32.],\n",
       "       [33.],\n",
       "       [34.],\n",
       "       [35.],\n",
       "       [36.],\n",
       "       [37.],\n",
       "       [38.],\n",
       "       [39.],\n",
       "       [40.],\n",
       "       [41.],\n",
       "       [42.],\n",
       "       [43.],\n",
       "       [44.],\n",
       "       [45.],\n",
       "       [46.],\n",
       "       [47.],\n",
       "       [48.],\n",
       "       [49.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = tf.range(50, dtype=tf.float32)[:, tf.newaxis]\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c792b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6146962a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "         11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "         22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "         33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "         44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "         55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "         66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "         77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "         88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "         99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "        110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "        121., 122., 123., 124., 125., 126., 127.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.range(128, dtype=tf.float32)[tf.newaxis, :]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8ad304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2ba21",
   "metadata": {},
   "source": [
    "2개의 tensor가 직사각형을 만들어서 2차원 행렬이 됐다. 계산은 두 개의 벡터가 행렬 곱을 한 결과이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de57424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pos * i).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241589a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 128), dtype=float32, numpy=\n",
       "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.000e+00, 2.000e+00, ..., 1.250e+02, 1.260e+02,\n",
       "        1.270e+02],\n",
       "       [0.000e+00, 2.000e+00, 4.000e+00, ..., 2.500e+02, 2.520e+02,\n",
       "        2.540e+02],\n",
       "       ...,\n",
       "       [0.000e+00, 4.700e+01, 9.400e+01, ..., 5.875e+03, 5.922e+03,\n",
       "        5.969e+03],\n",
       "       [0.000e+00, 4.800e+01, 9.600e+01, ..., 6.000e+03, 6.048e+03,\n",
       "        6.096e+03],\n",
       "       [0.000e+00, 4.900e+01, 9.800e+01, ..., 6.125e+03, 6.174e+03,\n",
       "        6.223e+03]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37228e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pos * (1/tf.pow(10000, (2 * (i//2)) / tf.cast(128, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efef23fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 128), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 1.0000000e+00, 8.6596435e-01, ..., 1.3335215e-04,\n",
       "        1.1547819e-04, 1.1547819e-04],\n",
       "       [2.0000000e+00, 2.0000000e+00, 1.7319287e+00, ..., 2.6670430e-04,\n",
       "        2.3095639e-04, 2.3095639e-04],\n",
       "       ...,\n",
       "       [4.7000000e+01, 4.7000000e+01, 4.0700325e+01, ..., 6.2675509e-03,\n",
       "        5.4274751e-03, 5.4274751e-03],\n",
       "       [4.8000000e+01, 4.8000000e+01, 4.1566288e+01, ..., 6.4009032e-03,\n",
       "        5.5429535e-03, 5.5429535e-03],\n",
       "       [4.9000000e+01, 4.9000000e+01, 4.2432255e+01, ..., 6.5342556e-03,\n",
       "        5.6584314e-03, 5.6584314e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86b1eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11bd709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sines = tf.math.sin(angles[:, 0::2])  # 짝수번째 열은 sine\n",
    "cosines = tf.math.cos(angles[:, 1::2])   # 홀수번째 열은 cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaaba65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_rads = np.zeros(angles.shape)\n",
    "angle_rads[:, 0::2] = sines\n",
    "angle_rads[:, 1::2] = cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c944df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_rads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827aec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = tf.constant(angle_rads)\n",
    "pos_encoding = pos_encoding[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b3e56a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50, 128), dtype=float64, numpy=\n",
       "array([[[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "        [ 8.41470957e-01,  5.40302277e-01,  7.61720419e-01, ...,\n",
       "          1.00000000e+00,  1.15478193e-04,  1.00000000e+00],\n",
       "        [ 9.09297407e-01, -4.16146815e-01,  9.87046242e-01, ...,\n",
       "          9.99999940e-01,  2.30956386e-04,  1.00000000e+00],\n",
       "        ...,\n",
       "        [ 1.23573124e-01, -9.92335498e-01,  1.39918879e-01, ...,\n",
       "          9.99980330e-01,  5.42744854e-03,  9.99985278e-01],\n",
       "        [-7.68254697e-01, -6.40144348e-01, -6.63572073e-01, ...,\n",
       "          9.99979496e-01,  5.54292509e-03,  9.99984622e-01],\n",
       "        [-9.53752637e-01,  3.00592542e-01, -9.99784648e-01, ...,\n",
       "          9.99978662e-01,  5.65840118e-03,  9.99983966e-01]]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3e735bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 50, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ff063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)  # transpose_b=True => 2번째 행렬을 전치한 후 계산한다\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)  # k의 마지막 차원의 루트값으로 scaling한다\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)   # (QK^T)/sqrt(d_k)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10f01d",
   "metadata": {},
   "source": [
    "Q, K, V 에 대해 scaled dot product attention 실행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a814e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=tf.float32)\n",
    "temp_v = tf.constant([[   1, 0],\n",
    "                      [  10, 0],\n",
    "                      [ 100, 5],\n",
    "                      [1000, 6]], dtype=tf.float32)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d12d85",
   "metadata": {},
   "source": [
    "위 예시에서 Q는 temp_k의 2번째 행과 동일하다. 즉, 위의 경우 token이 4개가 있고 Q는 2번째 단어라는 뜻이다. (첫 단어는 \\<sos\\> 이니 사실상 문장의 첫 단어라고 봐도 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aef6d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out, temp_attention = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_out)\n",
    "print(temp_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3faf5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480875e7",
   "metadata": {},
   "source": [
    "이번에는 Q의 값이 K의 3,4번째 값과 모두 유사하다는 attention distribution이 나온 결과이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1803c",
   "metadata": {},
   "source": [
    "3개의 Query 값 사용(3개의 단어를 한꺼번에 연산한다). 이때 열의 차원은 $d_{model} / num\\_heads$ 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "762a6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.5 0.5]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [550.    5.5]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attention = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attention)\n",
    "print(temp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc976b8",
   "metadata": {},
   "source": [
    "각 token(query)마다 서로 다른 attention distribution 및 attention value가 나오는 걸 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb57c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        # Q, K, V의 열 차원 크기\n",
    "        # 나중에 다시 concat을 통해 원래 차원 복구 예정\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3]) # 모양을 (batch_size, num_heads, query/key/value 문장 길이, d_model/num_heads)로 만들기\n",
    "\n",
    "    # input으로 dictionary가 들어올 예정, key값은 각각 \"query\", \"key\", \"value\", \"mask\"가 있다.\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77331138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4bfb1",
   "metadata": {},
   "source": [
    "뒤에 있는 두 개의 단어가 padding된 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdca7594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1, 21, 777, 0, 0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17f4aa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0., 0., 0., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.math.equal(tf.constant([[1, 21, 777, 0, 0]]),0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821973e5",
   "metadata": {},
   "source": [
    "mask를 구현할 때 원소값이 0인 곳만 masking 할 거다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b213a198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.cast(tf.math.equal(tf.constant([[1, 21, 777, 0, 0]]),0), dtype=tf.float32)\n",
    "mask[:, tf.newaxis, tf.newaxis, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa159fc5",
   "metadata": {},
   "source": [
    "원래 shape (1, 5)의 1과 5 사이에 차원 2개를 새로 추가해서 shape이 (1, 1, 1, 5) 가 됐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca021842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fd536a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "        'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "        'mask': padding_mask # 패딩 마스크 사용\n",
    "    })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d475a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "            )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91d81884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bc902",
   "metadata": {},
   "source": [
    "create look ahead mask를 follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e70bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1, 2, 0, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b45c14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "262d65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = x.shape[1] # x = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e16c67",
   "metadata": {},
   "source": [
    "one-matrix의 lower triangle만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0dc28e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537bdb5",
   "metadata": {},
   "source": [
    "주대각선을 제외한 upper triangle만 남기기.\n",
    "\n",
    "upper triangle에 해당하는 파트는 sequence 입장에서 미래시이기 때문에 가려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03abb60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bcd77",
   "metadata": {},
   "source": [
    "padding mask와 look ahead mask가 둘 다 있는 모습:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9946762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "091be7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 패딩 마스크(두번째 서브층)\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f423f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9924cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f620a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e548e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    # multiclass classification 문제\n",
    "    # cross entropy 사용\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9f747",
   "metadata": {},
   "source": [
    "$$lrate = d^{-0.5}_{model} \\times min(step\\_num^{-0.5}, step\\_num \\times warmup\\_steps^{-1.5})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2fe2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ec57832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGwCAYAAACAZ5AeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoX0lEQVR4nO3de1hU1f4/8PcMMDNcBxFhQBFR8Y6XvBCmWUlhWkl1Sj1+08y0+lnpwcr0KJ48dvCo3SzL7KadMs1Ox8qMMtRKJVREzWteULwNCMgM1xmYWb8/YLaOIjI4w1x8v55nnmH2/uy912KS9WmttdeWCSEEiIiIiOiGyJ1dACIiIiJPwKSKiIiIyA6YVBERERHZAZMqIiIiIjtgUkVERERkB0yqiIiIiOyASRURERGRHXg7uwCezGw249y5cwgMDIRMJnN2cYiIiKgRhBAoLS1FZGQk5PLG9z8xqXKgc+fOISoqytnFICIioiY4ffo02rRp0+h4JlUOFBgYCKD2SwkKCnJyaYiIiKgx9Ho9oqKipHa8sZhUOZBlyC8oKIhJFRERkZuxdeoOJ6oTERER2QGTKiIiIiI7YFJFREREZAdMqoiIiIjsgEkVERERkR0wqSIiIiKyAyZVRERERHbApIqIiIjIDphUEREREdkBkyoiIiIiO3B6UrV06VK0a9cOKpUK8fHx2LFjR4Pxa9euRZcuXaBSqRAXF4cNGzZY7RdCIDU1FREREfD19UViYiKOHj1qFfPqq69i4MCB8PPzQ3BwcIPXKyoqQps2bSCTyVBSUtKUKhIREdFNwKlJ1Zo1a5CSkoK5c+di9+7d6NWrF5KSklBQUFBv/Pbt2zFmzBhMnDgROTk5SE5ORnJyMvbv3y/FLFy4EEuWLMGyZcuQlZUFf39/JCUloaqqSooxGo145JFH8Mwzz1y3jBMnTkTPnj1vvLJERETk0WRCCOGsi8fHx6N///545513AABmsxlRUVF47rnn8PLLL18VP2rUKJSXl2P9+vXStltvvRW9e/fGsmXLIIRAZGQkpk+fjhdeeAEAoNPpEB4ejhUrVmD06NFW51uxYgWmTZt2zR6o9957D2vWrEFqaiqGDh2KixcvNtizZTAYYDAYpM+Wp1zrdLpmf6CyySxQYzZD6e3VrNclIiJyd3q9Hmq12ub222k9VUajEdnZ2UhMTLxUGLkciYmJyMzMrPeYzMxMq3gASEpKkuJzc3Oh1WqtYtRqNeLj4695zms5ePAg5s2bh08//RRyeeN+TWlpaVCr1dIrKirKpmva01+WbUe/f/6MckON08pARER0M3FaUlVYWAiTyYTw8HCr7eHh4dBqtfUeo9VqG4y3vNtyzvoYDAaMGTMGixYtQtu2bRt93MyZM6HT6aTX6dOnG32sveXklaDUUIOdJ4udVgYiIqKbibezC+CKZs6cia5du+L//u//bDpOqVRCqVQ6qFSNd/mIrqHG7MSSEBER3Tyc1lMVGhoKLy8v5OfnW23Pz8+HRqOp9xiNRtNgvOXdlnPWZ9OmTVi7di28vb3h7e2NoUOHSmWeO3duo8/jLNUmJlVERETNzWlJlUKhQN++fZGRkSFtM5vNyMjIQEJCQr3HJCQkWMUDwMaNG6X4mJgYaDQaqxi9Xo+srKxrnrM+//3vf7F3717s2bMHe/bswYcffggA+O233zBlypRGn8dZjKZLiZSh2uTEkhAREd08nDr8l5KSgvHjx6Nfv34YMGAA3nzzTZSXl2PChAkAgHHjxqF169ZIS0sDAEydOhVDhgzBa6+9hhEjRmD16tXYtWsXli9fDgCQyWSYNm0a5s+fj9jYWMTExGDOnDmIjIxEcnKydN28vDwUFxcjLy8PJpMJe/bsAQB07NgRAQEB6NChg1U5CwsLAQBdu3a97rpWrsB4We9UFXuqiIiImoVTk6pRo0bhwoULSE1NhVarRe/evZGeni5NNM/Ly7O6827gwIFYtWoVZs+ejVmzZiE2Nhbr1q1Djx49pJiXXnoJ5eXlmDx5MkpKSjBo0CCkp6dDpVJJMampqVi5cqX0uU+fPgCAzZs344477nBwrR2v+rKeKt79R0RE1Dycuk6Vp2vqOhc36nRxBQYv3AwAmHJnB7yY1KXZrk1EROTu3G6dKnKcyyenl1axp4qIiKg5MKnyQJfPqdJXVjuxJERERDcPJlUe6PK7/9hTRURE1DyYVHkgI4f/iIiImh2TKg9kNfxXxeE/IiKi5sCkygMZTZcW/GRPFRERUfNgUuWBjDWXVslgTxUREVHzYFLlgS6fqF5mqIHZzKXIiIiIHI1JlQe6fE6VEECZkUOAREREjsakygMZr3jeH+dVEREROR6TKg9krDFZfS7lvCoiIiKHY1LlgS6fUwUA+kr2VBERETkakyoPdPXwH3uqiIiIHI1JlQfinCoiIqLmx6TKAxlN1ksocK0qIiIix2NS5YGu7KnSVTCpIiIicjQmVR7o8sfUAMBFJlVEREQOx6TKA1l6qoJU3gCAkkqjM4tDRER0U2BS5YEsSVV4kAoAh/+IiIiaA5MqD2RZpyosSAkAuFjBnioiIiJHY1LlgSw9VWGBtT1VJZXsqSIiInI0JlUeyLKkQlhgbU8Vh/+IiIgcj0mVB7I8+69VXVJVUlkNIURDhxAREdENYlLlgaThv7qJ6iazQKmBq6oTERE5EpMqD2SZqB6o8oavjxcADgESERE5GpMqD2TpqVJ6yRHs5wOAdwASERE5GpMqD2RJqhTecgT7KQAAJeypIiIicigmVR7IklT5eMkR7MueKiIioubApMoDWeZU1fZU1SZVOq5VRURE5FBMqjwQh/+IiIiaH5MqDyT1VHGiOhERUbNhUuWBpLv/vOVoYRn+Y08VERGRQzGp8jA1JjPMdYunK7zlCPatHf5jTxUREZFjManyMJahP6A2qWrhX5tUFbOnioiIyKGYVHkYy9AfUDunqmVAbVJVVGZwVpGIiIhuCkyqPIwlqZLJAC+5DKH+tQ9VLirj8B8REZEjManyMIaaS3f+yWQyqaeqstqECiMfqkxEROQoTk+qli5dinbt2kGlUiE+Ph47duxoMH7t2rXo0qULVCoV4uLisGHDBqv9QgikpqYiIiICvr6+SExMxNGjR61iXn31VQwcOBB+fn4IDg6+6hp79+7FmDFjEBUVBV9fX3Tt2hVvvfXWDde1OVRftvAnAPgpvKCs+5m9VURERI7j1KRqzZo1SElJwdy5c7F792706tULSUlJKCgoqDd++/btGDNmDCZOnIicnBwkJycjOTkZ+/fvl2IWLlyIJUuWYNmyZcjKyoK/vz+SkpJQVVUlxRiNRjzyyCN45pln6r1OdnY2wsLC8Nlnn+HAgQP4+9//jpkzZ+Kdd96x7y/AASwT1S2JlEwmQ2hA3RBgOZMqIiIiR5EJIYSzLh4fH4/+/ftLyYrZbEZUVBSee+45vPzyy1fFjxo1CuXl5Vi/fr207dZbb0Xv3r2xbNkyCCEQGRmJ6dOn44UXXgAA6HQ6hIeHY8WKFRg9erTV+VasWIFp06ahpKTkumWdMmUKDh06hE2bNl0zxmAwwGC4NCFcr9cjKioKOp0OQUFB172GPew7U4IH3tmGSLUK22cOBQA88M5W7Dujw0fj+2Fo1/BmKQcREZG70uv1UKvVNrffTuupMhqNyM7ORmJi4qXCyOVITExEZmZmvcdkZmZaxQNAUlKSFJ+bmwutVmsVo1arER8ff81zNpZOp0NISEiDMWlpaVCr1dIrKirqhq7ZFJc/osaipb/lDkD2VBERETmK05KqwsJCmEwmhIdb95yEh4dDq9XWe4xWq20w3vJuyzkbY/v27VizZg0mT57cYNzMmTOh0+mk1+nTp5t8zaaqN6mqG/4rLOeyCkRERI7i7ewCuLr9+/dj5MiRmDt3Lu65554GY5VKJZRKZTOVrH4GU31JFXuqiIiIHM1pPVWhoaHw8vJCfn6+1fb8/HxoNJp6j9FoNA3GW95tOWdDDh48iKFDh2Ly5MmYPXu2zcc7g6WnyservuE/9lQRERE5itOSKoVCgb59+yIjI0PaZjabkZGRgYSEhHqPSUhIsIoHgI0bN0rxMTEx0Gg0VjF6vR5ZWVnXPOe1HDhwAHfeeSfGjx+PV1991aZjncl42TpVFi39efcfERGRozl1+C8lJQXjx49Hv379MGDAALz55psoLy/HhAkTAADjxo1D69atkZaWBgCYOnUqhgwZgtdeew0jRozA6tWrsWvXLixfvhxA7fIB06ZNw/z58xEbG4uYmBjMmTMHkZGRSE5Olq6bl5eH4uJi5OXlwWQyYc+ePQCAjh07IiAgAPv378ddd92FpKQkpKSkSPOxvLy80KpVq+b7BTXBletUARz+IyIiag5OTapGjRqFCxcuIDU1FVqtFr1790Z6ero00TwvLw9y+aXkYODAgVi1ahVmz56NWbNmITY2FuvWrUOPHj2kmJdeegnl5eWYPHkySkpKMGjQIKSnp0OlUkkxqampWLlypfS5T58+AIDNmzfjjjvuwFdffYULFy7gs88+w2effSbFRUdH4+TJk476ddiFpadKeVlSdWmdKg7/EREROYpT16nydE1d5+JGfJp5EqnfHMDwOA3eHdsXAHBeV4mEtE3wlstw9NV7IZPJmqUsRERE7sjt1qkix6hvTlVI3UT1GrOArrLaKeUiIiLydEyqPIyhnnWqlN5eCFLVjvQW8g5AIiIih2BS5WHqW/wTAMKDaueU5euZVBERETkCkyoPY3mg8uXrVAGXJ1VVVx1DREREN45JlYe5Vk9VWGDtHYAFpeypIiIicgQmVR7Gsk6V8oqeqjD2VBERETkUkyoPc+05VXU9VZxTRURE5BBMqjzMtYf/2FNFRETkSEyqPIzBdPU6VcBlPVWcU0VEROQQTKo8zKWeKi+r7Zff/cdF9ImIiOyPSZWHsSRVPl7Wj6JpVXf3n6HGDH1lTbOXi4iIyNMxqfIw15pTpfLxgtrXBwCQX8p5VURERPbGpMrDSEsqeF/91fIOQCIiIsdhUuVhLCuqX9lTBXBVdSIiIkdiUuVhpOE/L6+r9knLKnD4j4iIyO6YVHmYa82pAi4N/2l1TKqIiIjsjUmVhzE0kFRFBvsCAM6VMKkiIiKyNyZVHsZ4jcU/AaC1lFRVNmuZiIiIbgZMqjzMpeE/2VX7pJ4qHZMqIiIie2NS5WEamqgeGVw7Ub2kohrlBi4ASkREZE9MqjxMdQNLKgSqfBCo8gYAnGdvFRERkV0xqfIgZrNAjbn2uX71JVXApXlVZzlZnYiIyK6YVHkQyyR14NpJVSQnqxMRETkEkyoPYllOAaj/7j/g0rwqJlVERET2xaTKgxgvS6p8vK6++w+41FN1lkkVERGRXTGp8iCXP/dPJqs/qeJaVURERI7BpMqDXFpO4dpfK1dVJyIicgwmVR6koef+WViSqvO6Spjr7hQkIiKiG8ekyoNUN/CIGovwQCW85DJUmwQKSg3NVTQiIiKPx6TKgzT0MGULby+5dAdgXnFFs5SLiIjoZsCkyoM0ZvgPAKJD/AEAp4rKHV4mIiKimwWTKg9ibMTwHwC0bekHgD1VRERE9sSkyoM0vqeqNqk6VcSkioiIyF6YVHmQRidVdT1Vp9hTRUREZDdMqjyI0WQCcP3hv6i6nqo8zqkiIiKyGyZVHqTxPVW1E9UvVlRDX1Xt8HIRERHdDJhUeRCjqXYxz+v1VAUovdHSXwEAyOO8KiIiIrtwelK1dOlStGvXDiqVCvHx8dixY0eD8WvXrkWXLl2gUqkQFxeHDRs2WO0XQiA1NRURERHw9fVFYmIijh49ahXz6quvYuDAgfDz80NwcHC918nLy8OIESPg5+eHsLAwvPjii6ipqbmhujpaY3uqAN4BSEREZG9OTarWrFmDlJQUzJ07F7t370avXr2QlJSEgoKCeuO3b9+OMWPGYOLEicjJyUFycjKSk5Oxf/9+KWbhwoVYsmQJli1bhqysLPj7+yMpKQlVVZeedWc0GvHII4/gmWeeqfc6JpMJI0aMgNFoxPbt27Fy5UqsWLECqamp9v0F2JktSRXvACQiIrIz4UQDBgwQU6ZMkT6bTCYRGRkp0tLS6o1/9NFHxYgRI6y2xcfHi6eeekoIIYTZbBYajUYsWrRI2l9SUiKUSqX44osvrjrfJ598ItRq9VXbN2zYIORyudBqtdK29957TwQFBQmDwdDo+ul0OgFA6HS6Rh9zI97c+KeInrFezPx633VjX/vpiIiesV68/N+9zVAyIiIi99HU9ttpPVVGoxHZ2dlITEyUtsnlciQmJiIzM7PeYzIzM63iASApKUmKz83NhVartYpRq9WIj4+/5jmvdZ24uDiEh4dbXUev1+PAgQPXPM5gMECv11u9mlNj7/4DLvVU5RbyDkAiIiJ7cFpSVVhYCJPJZJW4AEB4eDi0Wm29x2i12gbjLe+2nNOW61x+jfqkpaVBrVZLr6ioqEZf0x4sw3/KRgz/dQgLAACcuMCkioiIyB6cPlHdk8ycORM6nU56nT59ulmvb0mqfBrRU9W+Ve2yCgWlBi6rQEREZAdOS6pCQ0Ph5eWF/Px8q+35+fnQaDT1HqPRaBqMt7zbck5brnP5NeqjVCoRFBRk9WpO0rP/GtFTFaTyQVigEgB7q4iIiOzBaUmVQqFA3759kZGRIW0zm83IyMhAQkJCvcckJCRYxQPAxo0bpfiYmBhoNBqrGL1ej6ysrGue81rX+eOPP6zuQty4cSOCgoLQrVu3Rp+nuRlr6tapakRSBQAdWtUOAR4vKHNYmYiIiG4W3s68eEpKCsaPH49+/fphwIABePPNN1FeXo4JEyYAAMaNG4fWrVsjLS0NADB16lQMGTIEr732GkaMGIHVq1dj165dWL58OQBAJpNh2rRpmD9/PmJjYxETE4M5c+YgMjISycnJ0nXz8vJQXFyMvLw8mEwm7NmzBwDQsWNHBAQE4J577kG3bt3w2GOPYeHChdBqtZg9ezamTJkCpVLZrL8jW0g9VY0Y/gOADmH+yDxRhOMXmFQRERHdKKcmVaNGjcKFCxeQmpoKrVaL3r17Iz09XZoUnpeXB7n8UoIwcOBArFq1CrNnz8asWbMQGxuLdevWoUePHlLMSy+9hPLyckyePBklJSUYNGgQ0tPToVKppJjU1FSsXLlS+tynTx8AwObNm3HHHXfAy8sL69evxzPPPIOEhAT4+/tj/PjxmDdvnqN/JTfEWFN395+tPVVMqoiIiG6YTAghnF0IT6XX66FWq6HT6ZplftWET3Zg85ELWPiXnni03/XvPPz1zwsY9/EOdAwLwM8pQxxePiIiInfQ1Pabd/95EMvwX2OWVAAuLatwqqgc1XXHEhERUdMwqfIgtiypAAARQSr4+nih2iRwms8AJCIiuiFMqjyI9Oy/RiZVcrlMWq/qGO8AJCIiuiFMqjyI0WTbkgoAEFs3BHiUSRUREdENYVLlQWy9+w8AukTUTsA7dL55n1NIRETkaZhUeRBbVlS36KIJBAAc1pY6pExEREQ3CyZVHsTWOVUA0EVT21OVW1iOqmqTQ8pFRER0M2BS5UEsSVVjl1QAgPAgJYL9fGAyC05WJyIiugFMqjyI1FNlQ1Ilk8k4BEhERGQHTKo8iGVOVWPXqbKwDAEe5mR1IiKiJmNS5SHMZoHqJiypAABdI9hTRUREdKOYVHmIavOlx8zYmlRJPVVa9lQRERE1FZMqD2GZTwXYdvcfAHQKD4RMBhSWGVFQWmXvohEREd0UmFR5iBtJqnwVXmgfWvu4mgNn2VtFRETUFEyqPMSlSeoyyOUym4/v1SYYALDvjM6exSIiIrppMKnyEE1Z+PNycW3UAIA/zpbYq0hEREQ3FSZVHqIpa1RdrmddUsWeKiIioqZhUuUhDDVNW6PKoluEGnIZUFBqgFbHyepERES2uqGkqqqKja+raMrDlC/nq/BCp/Da9ar2nSmxV7GIiIhuGja3wGazGf/85z/RunVrBAQE4MSJEwCAOXPm4KOPPrJ7Aalxqm9w+A+4NAT4x1kOARIREdnK5hZ4/vz5WLFiBRYuXAiFQiFt79GjBz788EO7Fo4aT+qpauLwHwDE8Q5AIiKiJrO5Bf7000+xfPlyjB07Fl5eXtL2Xr164fDhw3YtHDWeZaK68kZ6qlpbJquXQAhhl3IRERHdLGxugc+ePYuOHTtetd1sNqO6utouhSLb3ejdfwDQJSIQCm85LlZU42RRhb2KRkREdFOwuQXu1q0bfvvtt6u2f/XVV+jTp49dCkW2u9GJ6gCg9PaSeqt2nSy2S7mIiIhuFt62HpCamorx48fj7NmzMJvN+Prrr3HkyBF8+umnWL9+vSPKSI1guMHFPy36tmuBXacuIvvURTzSL8oeRSMiIrop2NwCjxw5Et999x1+/vln+Pv7IzU1FYcOHcJ3332Hu+++2xFlpEYw3uA6VRb9okMAALtOXbzhMhEREd1MbO6pAoDBgwdj48aN9i4L3QB7zKkCgL7RLQAAxwrKUFJhRLCf4jpHEBEREdCEnqr27dujqKjoqu0lJSVo3769XQpFtqu2w5wqAAjxV6B9K38AQDZ7q4iIiBrN5hb45MmTMJlMV203GAw4e/asXQpFtrPHkgoW/ep6qzgESERE1HiNHv779ttvpZ9//PFHqNVq6bPJZEJGRgbatWtn18JR49lj8U+LftEh+HLXGWSfZFJFRETUWI1OqpKTkwEAMpkM48ePt9rn4+ODdu3a4bXXXrNr4ajx7DWnCgD6tavtqdpzpgRV1SaofLyucwQRERE1Oqkym2sb7ZiYGOzcuROhoaEOKxTZzmDHpCom1B9hgUoUlBqw+9RFDOzI75qIiOh6bG6Bc3NzmVC5oEvDfzfeqySTyXBbXSK17XjhDZ+PiIjoZtCkJRXKy8vxyy+/IC8vD0aj0Wrf888/b5eCkW2kdaq8ZXY538AOLfG/nLPYfvzqOz2JiIjoajYnVTk5ORg+fDgqKipQXl6OkJAQFBYWws/PD2FhYUyqnKTajhPVAUhDfvvO6FBaVY1AlY9dzktEROSpbG6B//a3v+H+++/HxYsX4evri99//x2nTp1C3759sXjxYkeUkRrBnksqAEDrYF+0a+kHk1kg6wSfA0hERHQ9NrfAe/bswfTp0yGXy+Hl5QWDwYCoqCgsXLgQs2bNckQZqRHsefefhaW3ikOARERE12dzC+zj4wO5vPawsLAw5OXlAQDUajVOnz5tcwGWLl2Kdu3aQaVSIT4+Hjt27Ggwfu3atejSpQtUKhXi4uKwYcMGq/1CCKSmpiIiIgK+vr5ITEzE0aNHrWKKi4sxduxYBAUFITg4GBMnTkRZWZlVzI8//ohbb70VgYGBaNWqFR5++GGcPHnS5vo1F6OdVlS/3MAOLQEA2zlZnYiI6LpsboH79OmDnTt3AgCGDBmC1NRUfP7555g2bRp69Ohh07nWrFmDlJQUzJ07F7t370avXr2QlJSEgoKCeuO3b9+OMWPGYOLEicjJyUFycjKSk5Oxf/9+KWbhwoVYsmQJli1bhqysLPj7+yMpKQlVVVVSzNixY3HgwAFs3LgR69evx6+//orJkydL+3NzczFy5Ejcdddd2LNnD3788UcUFhbioYcesql+zUlaUsEOd/9ZDOwQCpkMOKwtRb6+6voHEBER3cyEjXbu3Ck2bdokhBAiPz9fJCUlicDAQHHLLbeInJwcm841YMAAMWXKFOmzyWQSkZGRIi0trd74Rx99VIwYMcJqW3x8vHjqqaeEEEKYzWah0WjEokWLpP0lJSVCqVSKL774QgghxMGDBwUAsXPnTinmhx9+EDKZTJw9e1YIIcTatWuFt7e3MJlMUsy3334rZDKZMBqNja6fTqcTAIROp2v0MU018p2tInrGevHTAa1dz/tA3Xm/yDpl1/MSERG5qqa23zb3VPXr1w933nkngNrhv/T0dOj1emRnZ6N3796NPo/RaER2djYSExOlbXK5HImJicjMzKz3mMzMTKt4AEhKSpLic3NzodVqrWLUajXi4+OlmMzMTAQHB6Nfv35STGJiIuRyObKysgAAffv2hVwuxyeffAKTyQSdTof//Oc/SExMhI/Pte+CMxgM0Ov1Vq/mIi2p4GWfJRUs7uocBgDYdLj+3kMiIiKqZbcJOLt378Z9993X6PjCwkKYTCaEh4dbbQ8PD4dWq633GK1W22C85f16MWFhYVb7vb29ERISIsXExMTgp59+wqxZs6BUKhEcHIwzZ87gyy+/bLBOaWlpUKvV0isqKqrBeHtyxJwqALirS+3vauuxQhhqrn6QNhEREdWyqQX+8ccf8cILL2DWrFk4ceIEAODw4cNITk5G//79pUfZuDutVotJkyZh/Pjx2LlzJ3755RcoFAr85S9/gRDimsfNnDkTOp1OejVl4n5TWdapsteSChbdI4PQKlCJCqMJO3K5tAIREdG1NHrxz48++giTJk1CSEgILl68iA8//BCvv/46nnvuOYwaNQr79+9H165dG33h0NBQeHl5IT8/32p7fn4+NBpNvcdoNJoG4y3v+fn5iIiIsIqxDE1qNJqrJsLX1NSguLhYOn7p0qVQq9VYuHChFPPZZ58hKioKWVlZuPXWW+stn1KphFKpvF7VHcLogInqACCXy3Bn51b4ctcZbD58AYNjW9n1/ERERJ6i0d0ab731Fv7973+jsLAQX375JQoLC/Huu+/ijz/+wLJly2xKqABAoVCgb9++yMjIkLaZzWZkZGQgISGh3mMSEhKs4gFg48aNUnxMTAw0Go1VjF6vR1ZWlhSTkJCAkpISZGdnSzGbNm2C2WxGfHw8AKCiokJaNsLCqy5ZcdXeOEesU2VxZ928qs1HOK+KiIjomho7o93Pz0/k5uYKIWrvsvPx8RFbt261aVb8lVavXi2USqVYsWKFOHjwoJg8ebIIDg4WWm3tHWyPPfaYePnll6X4bdu2CW9vb7F48WJx6NAhMXfuXOHj4yP++OMPKWbBggUiODhYfPPNN2Lfvn1i5MiRIiYmRlRWVkoxw4YNE3369BFZWVli69atIjY2VowZM0ban5GRIWQymXjllVfEn3/+KbKzs0VSUpKIjo4WFRUVja5fc9791yM1XUTPWC9OXCiz+7n1lUbRcdb3InrGenGsoNTu5yciInIlDr/7r7KyEn5+fgAAmUwGpVJpNcTWFKNGjcLixYuRmpqK3r17Y8+ePUhPT5cmmufl5eH8+fNS/MCBA7Fq1SosX74cvXr1wldffYV169ZZrY/10ksv4bnnnsPkyZPRv39/lJWVIT09HSqVSor5/PPP0aVLFwwdOhTDhw/HoEGDsHz5cmn/XXfdhVWrVmHdunXo06cPhg0bBqVSifT0dPj6+t5QnR3F4KCJ6gAQqPLBwA61q6un76//JgIiIqKbnUyIBmZeX0Yul2P+/PkICAgAAMyYMQMvvvgiQkNDreL4QOVL9Ho91Go1dDodgoKCHHYdIQRiZtauLL/z74loFWj/eV1rduZhxn//QPfIIHz//GC7n5+IiMhVNLX9bnRS1a5dO8hkDa+BJJPJpLsCqfmSKmONGZ1m/wAA2Jt6D9R+115Lq6mKy43o/+rPMJkFfnnxDkS39Lf7NYiIiFxBU9vvRt/958rPvbvZWdaoAhwz/AcAIf4KJLRvia3HCvHDfi2eHtLBIdchIiJyV45pgalZVdc4PqkCgHvjapec+OGP89eJJCIiuvkwqfIAlp4qL7kMXnL7Pqbmcvd000AuA/ae0eHMxQqHXYeIiMgdManyAJcW/nTs19kqUIkBMSEAgPX72FtFRER0OSZVHsDgwIU/rzSyd2sAwNe7zzT4yB4iIqKbDZMqD+DI1dSvNDwuAgpvOf7ML8OBc3qHX4+IiMhd2NwK6/X6el+lpaUwGo2OKCNdh2VOlaOH/wBA7euDu7vWLs76v5yzDr8eERGRu7C5FQ4ODkaLFi2uegUHB8PX1xfR0dGYO3euyz4jzxM1Z08VADzYp3YI8Js951Bj4vdMREQE2LBOlcWKFSvw97//HY8//jgGDBgAANixYwdWrlyJ2bNn48KFC1i8eDGUSiVmzZpl9wLT1ZprorrFkM6tEOKvQGGZAb8dK5QeuExERHQzszmpWrlyJV577TU8+uij0rb7778fcXFxeP/995GRkYG2bdvi1VdfZVLVTKod+Ny/+vh4yfFAr0is2H4SX2WfYVJFRESEJgz/bd++HX369Llqe58+fZCZmQkAGDRoEPLy8m68dNQozXn3n8Uj/doAAH46oMWFUkOzXZeIiMhV2dwKR0VF4aOPPrpq+0cffYSoqCgAQFFREVq0aHHjpaNGac6J6hbdI9XoHRWMapPA2uzTzXZdIiIiV2Xz8N/ixYvxyCOP4IcffkD//v0BALt27cLhw4fx1VdfAQB27tyJUaNG2bekdE3NPVHdYmx8W+w5XYIvduTh6ds7QO7A1dyJiIhcnc2t8AMPPIDDhw/j3nvvRXFxMYqLi3Hvvffi8OHDuO+++wAAzzzzDF5//XW7F5bq56yk6r6ekQhSeeN0cSV+O1bYrNcmIiJyNTb3VAFATEwMFixYYO+yUBMZa0wAmj+p8lV44eG+bfDJtpP4/PdTGNKpVbNen4iIyJU0KakqKSnBjh07UFBQcNV6VOPGjbNLwajxnDGnymJsfFt8su0kfj6Uj9PFFYgK8Wv2MhAREbkCm5Oq7777DmPHjkVZWRmCgoIgk12aRyOTyZhUOUFzr1N1uY5hgRjUMRRbjxVixfaTmHNft2YvAxERkSuwuRWePn06nnjiCZSVlaGkpAQXL16UXsXFxY4oI12H0VT7YOPmHv6zeHJwDABgzc7T0FdVO6UMREREzmZzK3z27Fk8//zz8PPjMI+rcNZEdYshnVohNiwAZYYarN7B9cmIiOjmZHMrnJSUhF27djmiLNREzk6qZDKZ1Fv1ybaT0grvRERENxOb51SNGDECL774Ig4ePIi4uDj4+PhY7X/ggQfsVjhqHKOp7u4/J8ypshjZuzUW/XgE53VV+H7feSTXPXSZiIjoZmFzUjVp0iQAwLx5867aJ5PJYKpr4Kn5OLunCgBUPl4Yn9AOr238E0s3H8MDvSK5GCgREd1UbG6FzWbzNV9MqJzDmXf/XW7cwHYIVHnjaEEZNuw/79SyEBERNTfntsJkF9I6VU7sqQIAta8Pnritdm7VkoyjMJuFU8tDRETUnBo1/LdkyRJMnjwZKpUKS5YsaTD2+eeft0vBqPGMNc5dUuFyT9wWg4+35uLP/DKkH9BieFyEs4tERETULBqVVL3xxhsYO3YsVCoV3njjjWvGyWQyJlVO4MwV1a+k9vPBhNvaYcmmY1iScRTDums4t4qIiG4KjUqqcnNz6/2ZXIOznv13LU8MisEn207isLYU6/84jwd6RTq7SERERA7nGq0w3RBXuPvvcsF+Cky6vT0AYNGPh2Go4Q0MRETk+WxeUsFkMmHFihXIyMio94HKmzZtslvhqHFcZaL65Z4cHIPPfj+F08WV+Oz3PEwcFOPsIhERETmUza3w1KlTMXXqVJhMJvTo0QO9evWyelHzs/RUKV1gTpWFn8IbKXd3AgC8vekodJV8JiAREXk2m3uqVq9ejS+//BLDhw93RHmoCSxJlY8L9VQBwF/6tsFHW3NxtKAM7245hpn3dnV2kYiIiBzG5lZYoVCgY8eOjigLNZGrLP55JW8vOV6+twsA4JOtJ5FbWO7kEhERETmOza3w9OnT8dZbb0EILuzoKowm11mn6kp3dQnD7Z1awWgy4x/fHuB/N0RE5LFsHv7bunUrNm/ejB9++AHdu3e/6oHKX3/9td0KR43jaksqXE4mk+GVB7oj6Y1f8cufF/DTwXwkddc4u1hERER2Z3NSFRwcjAcffNARZaEmcqXFP+sTE+qPSbfHYOnm45j33UHcHtsKvgovZxeLiIjIrmxKqmpqanDnnXfinnvugUbD3gZXId3954I9VRZT7uyIdTnncLakEm9lHJXmWhEREXkKm1phb29vPP300zAYDHYrwNKlS9GuXTuoVCrEx8djx44dDcavXbsWXbp0gUqlQlxcHDZs2GC1XwiB1NRUREREwNfXF4mJiTh69KhVTHFxMcaOHYugoCAEBwdj4sSJKCsru+o8ixcvRqdOnaBUKtG6dWu8+uqr9qm0HdWYzLA8t9gVh/8s/BTemHt/NwDAB7+dwL4zJc4tEBERkZ3Z3AoPGDAAOTk5drn4mjVrkJKSgrlz52L37t3o1asXkpKSUFBQUG/89u3bMWbMGEycOBE5OTlITk5GcnIy9u/fL8UsXLgQS5YswbJly5CVlQV/f38kJSWhqqpKihk7diwOHDiAjRs3Yv369fj1118xefJkq2tNnToVH374IRYvXozDhw/j22+/xYABA+xSb3uyDP0Brp1UAcA93TW4r2cETGaBl77aJ/WwEREReQRhozVr1oj27duLt99+W2zfvl3s3bvX6mWLAQMGiClTpkifTSaTiIyMFGlpafXGP/roo2LEiBFW2+Lj48VTTz0lhBDCbDYLjUYjFi1aJO0vKSkRSqVSfPHFF0IIIQ4ePCgAiJ07d0oxP/zwg5DJZOLs2bNSjLe3tzh8+LBN9bmSTqcTAIROp7uh8zTkYrlBRM9YL6JnrBfGGpPDrmMvhaVVos+8n0T0jPXi9Z+OOLs4REREV2lq+21z18bo0aORm5uL559/Hrfddht69+6NPn36SO+NZTQakZ2djcTERGmbXC5HYmIiMjMz6z0mMzPTKh4AkpKSpPjc3FxotVqrGLVajfj4eCkmMzMTwcHB6NevnxSTmJgIuVyOrKwsAMB3332H9u3bY/369YiJiUG7du3w5JNPori4uME6GQwG6PV6q5ejWXp7ZDLAWy5z+PVuVMsAJV55oDsAYOnmYzh4zvG/IyIiouZgc1KVm5t71evEiRPSe2MVFhbCZDIhPDzcant4eDi0Wm29x2i12gbjLe/XiwkLC7Pa7+3tjZCQECnmxIkTOHXqFNauXYtPP/0UK1asQHZ2Nv7yl780WKe0tDSo1WrpFRUV1WC8PVx+559M5vpJFQDc1zMC93QLR41Z4G9r9qCqmg9cJiIi92fzkgrR0dGOKIdLMZvNMBgM+PTTT9GpU+3z6z766CP07dsXR44cQefOnes9bubMmUhJSZE+6/V6hydW0mrqLj6f6nIymQyvPhiH3XkXcSS/FP/acAjzRvZwdrGIiIhuiM1JlcXBgweRl5cHo9Fotf2BBx5o1PGhoaHw8vJCfn6+1fb8/PxrLteg0WgajLe85+fnIyIiwiqmd+/eUsyVE+FrampQXFwsHR8REQFvb28poQKArl1rn1uXl5d3zaRKqVRCqVQ2WG97s/RUufJyCvVpFajEa4/2xviPd+DTzFO4PbYVEruFX/9AIiIiF2VzS3zixAn06tULPXr0wIgRI6Q78B588EGbFgVVKBTo27cvMjIypG1msxkZGRlISEio95iEhASreADYuHGjFB8TEwONRmMVo9frkZWVJcUkJCSgpKQE2dnZUsymTZtgNpsRHx8PALjttttQU1OD48ePSzF//vknANfrqXPV5/41xpBOrfDkoBgAwItf7UW+vuo6RxAREbkum1viqVOnIiYmBgUFBfDz88OBAwfw66+/ol+/ftiyZYtN50pJScEHH3yAlStX4tChQ3jmmWdQXl6OCRMmAADGjRuHmTNnWl07PT0dr732Gg4fPox//OMf2LVrF5599lkAtcNK06ZNw/z58/Htt9/ijz/+wLhx4xAZGYnk5GQAtT1Ow4YNw6RJk7Bjxw5s27YNzz77LEaPHo3IyEgAtRPXb7nlFjzxxBPIyclBdnY2nnrqKdx9991WvVeuwB2H/y734rDO6B4ZhIsV1Xj+ixzUmLjMAhERuSlbbzNs2bKltHRCUFCQtOxARkaG6N27t62nE2+//bZo27atUCgUYsCAAeL333+X9g0ZMkSMHz/eKv7LL78UnTp1EgqFQnTv3l18//33VvvNZrOYM2eOCA8PF0qlUgwdOlQcOWJ9635RUZEYM2aMCAgIEEFBQWLChAmitLTUKubs2bPioYceEgEBASI8PFw8/vjjoqioyKa6NceSCtuOXhDRM9aLu1/f4rBrONrxglLRPTVdRM9YL+Z9d8DZxSEioptcU9tvmRBC2JKEtWjRArt370ZMTAw6dOiADz/8EHfeeSeOHz+OuLg4VFRUOCb7c0N6vR5qtRo6nQ5BQUEOucbmIwWY8MlOdI8MwvfPD3bINZpD+n4tnv6sdkj2rdG9MbJ3ayeXiIiIblZNbb9tHjPq0aMH9u7dCwCIj4/HwoULsW3bNsybNw/t27e39XR0g9x9+M9iWA8NptzZAQAw47/7uH4VERG5HZtb4tmzZ8Nsrm3I582bh9zcXAwePBgbNmzAkiVL7F5Aali1yX0nql8p5e7OuL1TK1RVmzH5P7twodR+z5gkIiJyNJuXVEhKSpJ+7tixIw4fPozi4mK0aNHCbRaf9CSe0lMFAF5yGZaM7o2RS7fhVFEFnvx0F1ZPuhW+Ci9nF42IiOi6mtwSHzt2DD/++CMqKysREhJizzKRDSxJlbutU3UtwX4KfPJ4fwT7+WDv6RJMW5MDk9mmaX9EREROYXNLXFRUhKFDh6JTp04YPnw4zp8/DwCYOHEipk+fbvcCUsOkx9R4SFIFAO1bBWD5Y/2g8JLjxwP5SNtwyNlFIiIiui6bW+K//e1v8PHxQV5eHvz8/KTto0aNQnp6ul0LR9fnzot/NmRATAgWPdITAPDh1lx8+FvjnytJRETkDDbPqfrpp5/w448/ok2bNlbbY2NjcerUKbsVjBrH4EFzqq40sndrnLlYiUU/HsH87w8hSOWDR/s7/iHVRERETWFzS1xeXm7VQ2VRXFzc7M+9o0s9VT4e1lNl8f/u6IBJg2sfZfPy1/vw/b7zTi4RERFR/WxuiQcPHoxPP/1U+iyTyWA2m7Fw4ULceeeddi0cXZ8nzqm6nEwmw6zhXTFmQBTMApi2JgebDudf/0AiIqJmZvPw38KFCzF06FDs2rULRqMRL730Eg4cOIDi4mJs27bNEWWkBlR78PCfhUwmw/zkOJQZTPhu7zk8/Z/deHfsLUjsFu7sohEREUmatKL6n3/+iUGDBmHkyJEoLy/HQw89hJycHHTo0MERZaQGWHqqlB46/GfhJZfh9Ud7YXicBkaTGU9/lo30/RwKJCIi12FzTxUAqNVq/P3vf7fadubMGUyePBnLly+3S8GocTxp8c/r8fGSY8noPvCW78W3e89hyqocvDVa4L6ekc4uGhERUdMX/7xSUVERPvroI3udjhrpZkqqAMDbS443RvXGQ31aw2QWeP6LHKzKynN2sYiIiOyXVJFzGDzo2X+N5SWXYdEjvaTJ67P+9wfe/PlPCMGV14mIyHlunpbYQ0lLKtwkPVUWXnIZ/vVgHJ6/qyMA4M2fj+Lv6/bzkTZEROQ0N1dL7IE8dUX1xpDJZEi5pzP+mdwDMhmwKisPT3+WjQpjjbOLRkREN6FGT1R/6KGHGtxfUlJyo2WhJqj28HWqGuOxW6PRKkCB51fvwcaD+fjLe5n4YHw/tA72dXbRiIjoJtLollitVjf4io6Oxrhx4xxZVqqHpadKeRMnVQAwrEcEvpgUj9AABQ6e12PkO1uRfarY2cUiIqKbSKN7qj755BNHloOayNNXVLdF3+gQfPPsIDy5chcOnddjzPIszH+wBx7tx+cFEhGR47EldnOX5lR5ObkkrqF1sC/++0wC7u1Ru0joS1/tw8yv96Gq2uTsohERkYdjUuXmbrZ1qhrDT+GNpX+9BX9L7ASZDPhix2k89O52nCwsd3bRiIjIg7EldnMGJlX1kstlmJoYi0+fGICW/rXzrO5/eysfbUNERA7DltjNWeZU+XjJnFwS1zQ4thW+f34w+kW3QKmhBk9/thszv/4D5QYuu0BERPbFpMrN8e6/69OoVfhi8q146vb2AIAvduRhxJLfsDvvopNLRkREnoQtsZuT1qniRPUG+XjJMXN4V6x6Mh6RahVOFlXgkWWZeH3jn9LvkIiI6EYwqXJznKhum4EdQ/HDtNsxsnckTGaBJRlH8fB723HovN7ZRSMiIjfHltiNmc0CNXXPumNS1XhqXx+8NboPlozpgyCVN/ad0eH+t7diYfphLr1ARERNxpbYjRkvG7ZiUmW7B3pFYmPKEAzrrkGNWeDdLcdx71u/IfN4kbOLRkREbogtsRuzLKcA3JwPVLaH8CAVlj3WF8v+ry/CApXILSzHmA9+x4yv9qGozODs4hERkRthS+zGjJclVVxS4cYM66HBz9OHYGx8WwDAml2ncefiLfhkWy4nshMRUaMwqXJj0nP/vOSQyZhU3agglQ9efTAOXz2dgG4RQdBX1eCV7w5i+Fu/YevRQmcXj4iIXByTKjfGO/8co1+7EHz33CD868E4hPgrcLSgDP/3URYmfboLp4r4qBsiIqofW2M3Jq1RxaTK7rzkMvw1vi02T78DE25rBy+5DBsP5iPx9V8w95v9uFDK+VZERGSNrbEbk3qqOEndYdR+Pph7f3ekTx2MIZ1aodoksDLzFIYs2ozXfzqC0qpqZxeRiIhcBFtjN8aHKTef2PBArHxiAFZNikevqGBUGE1YsukYbl+4GR/+dgKVRq5vRUR0s2Nr7MY4p6r5DewQinX/byCW/d8taN/KHxcrqjH/+0MY9O9NeG/LcZTxQc1ERDcttsZu7PK7/6j5yGQyDOsRgZ+m3Y5/PxyHqBBfFJUb8e/0wxj07014O+Mo9BwWJCK66bhEa7x06VK0a9cOKpUK8fHx2LFjR4Pxa9euRZcuXaBSqRAXF4cNGzZY7RdCIDU1FREREfD19UViYiKOHj1qFVNcXIyxY8ciKCgIwcHBmDhxIsrKyuq93rFjxxAYGIjg4OAbqqe9safKuby95BjVvy02Tb8Dix/phfah/iipqMZrG//EbQs24fWfjnABUSKim4jTW+M1a9YgJSUFc+fOxe7du9GrVy8kJSWhoKCg3vjt27djzJgxmDhxInJycpCcnIzk5GTs379film4cCGWLFmCZcuWISsrC/7+/khKSkJVVZUUM3bsWBw4cAAbN27E+vXr8euvv2Ly5MlXXa+6uhpjxozB4MGD7V/5G8SJ6q7Bx0uOv/Rtg40pQ/DW6N6IDQtAaVUNlmw6hoELNmHm13/gWEH9CTsREXkOmRBCOLMA8fHx6N+/P9555x0AgNlsRlRUFJ577jm8/PLLV8WPGjUK5eXlWL9+vbTt1ltvRe/evbFs2TIIIRAZGYnp06fjhRdeAADodDqEh4djxYoVGD16NA4dOoRu3bph586d6NevHwAgPT0dw4cPx5kzZxAZGSmde8aMGTh37hyGDh2KadOmoaSkpNF10+v1UKvV0Ol0CAoKasqvp0H/yzmDv63Zi0EdQ/HZk/F2Pz81jdkskH5Ai2W/HMe+Mzpp+11dwvDk4BgktG/JxVqJiFxYU9tvp3ZxGI1GZGdnIzExUdoml8uRmJiIzMzMeo/JzMy0igeApKQkKT43NxdardYqRq1WIz4+XorJzMxEcHCwlFABQGJiIuRyObKysqRtmzZtwtq1a7F06dJG1cdgMECv11u9HKm6pjYf5vCfa5HLZRgeF4FvptyGL59KwN3dwiGTAZsOF+CvH2Thvre3Ys3OPFQYOamdiMiTOLU1LiwshMlkQnh4uNX28PBwaLXaeo/RarUNxlverxcTFhZmtd/b2xshISFSTFFRER5//HGsWLGi0VlqWloa1Gq19IqKimrUcU1l4ER1lyaTyTAgJgQfjOuHjJQheOzWaKh85DhwTo8Z//0D8f/KwD++PYCj+aXOLioREdkBW+NrmDRpEv7617/i9ttvb/QxM2fOhE6nk16nT592YAk5Ud2dtG8VgH8m90Dmy0Mx894uiG7ph9KqGqzYfhJ3v/ErRr2fiW/3nrN6SDYREbkXb2dePDQ0FF5eXsjPz7fanp+fD41GU+8xGo2mwXjLe35+PiIiIqxievfuLcVcORG+pqYGxcXF0vGbNm3Ct99+i8WLFwOovaPQbDbD29sby5cvxxNPPHFV2ZRKJZRKZWOrf8OYVLmfFv4KPDWkAyYNbo+txwrx2e+n8POhfGTlFiMrtxihAQo83LcNHunbBh3DAp1dXCIisoFTW2OFQoG+ffsiIyND2mY2m5GRkYGEhIR6j0lISLCKB4CNGzdK8TExMdBoNFYxer0eWVlZUkxCQgJKSkqQnZ0txWzatAlmsxnx8bUTvjMzM7Fnzx7pNW/ePAQGBmLPnj148MEH7fMLuEFMqtyXXC7D7Z1aYfm4ftj28l14fmgswgKVKCwz4v1fTiDx9V8xcuk2/Of3U9BVcM0rIiJ34NSeKgBISUnB+PHj0a9fPwwYMABvvvkmysvLMWHCBADAuHHj0Lp1a6SlpQEApk6diiFDhuC1117DiBEjsHr1auzatQvLly8HUDuPZdq0aZg/fz5iY2MRExODOXPmIDIyEsnJyQCArl27YtiwYZg0aRKWLVuG6upqPPvssxg9erR051/Xrl2tyrlr1y7I5XL06NGjmX4z12c01T4ahXOq3FuE2hcpd3fCc3d1RMahAnyVfQabjxRg7+kS7D1dgn9+dxB3dwvHw31b4/bYVvDm901E5JKcnlSNGjUKFy5cQGpqKrRaLXr37o309HRponleXh7k8kuNyMCBA7Fq1SrMnj0bs2bNQmxsLNatW2eV7Lz00ksoLy/H5MmTUVJSgkGDBiE9PR0qlUqK+fzzz/Hss89i6NChkMvlePjhh7FkyZLmq7gdsKfKs/h4yTGshwbDemhwodSAb/acxVfZZ3BYW4rv/ziP7/84j5b+Ctwbp8H9PSPRv10I5HIuzUBE5Cqcvk6VJ3P0OlX/+PYAVmw/iWfv7IgXkjrb/fzkGg6c0+G/2WfxzZ6zKCo3Sts1QSrc1zMC9/eKRM82aq59RURkJ01tv53eU0VNZ2BP1U2he6Qa3SPVmDW8C7YfL8K3e8/hx/1aaPVV+HBrLj7cmou2IX4Y1kODpO7h6BPVgj1YREROwKTKjXH47+bi7SXH7Z1a4fZOrTA/uQd++fMCvtt7Dj8fykdecQWW/3oCy389gbBAJe7uFo6k7hrc2r4l//sgImomTKrcmJGLf960VD5eSOquQVJ3DcoNNfjlzwtI36/F5sMFKCg14POsPHyelYcglTeGdg1HUvdwDIpthQAl/8kTETkK/8K6MWNN3d1/7Im4qfkrvTE8LgLD4yJgqDEh83gRfjyQj40HtSgsM+J/OWfxv5yz8PGSoV90CO7s0gp3dA5DbFgA52EREdkRkyo3xuE/upLS2wt3dA7DHZ3DMD+5B3bnXcSP+7X4+VA+ThZVIPNEETJPFOFfGw6jdbAvhnRuhTs7h2Fgh5bwZy8WEdEN4V9RN8bhP2qIl1yG/u1C0L9dCGbf1w25heXYcqQAW45cQOaJIpwtqcSqrDysysqDwkuOATEhuKNzK9zRuRU6tGIvFhGRrZhUuTH2VJEtYkL9ERMagwm3xaDSaMLvJ4qw+UgBNh8pwOniSmw9Voitxwox//tDCA9SYmCHUCR0aInbOoaidbCvs4tPROTymFS5MaOpdokx9lSRrXwVXrizSxju7BIGIQROFJZj8+HaXqwdJ4uRrzdIc7EAoF1LPyR0CMVtHVsioX1LtAxovmdcEhG5CyZVbow9VWQPMpkMHVoFoEOrADw5uD2qqk3Yfeoith0vxPbjRdh3RoeTRRU4WZSHL3bkAQC6aAJrhxZjQtC/XQtEqNmTRUTEpMqN8e4/cgSVjxcGdgzFwI6hAAB9VTV2nCjG9uNF2H68EIe1pdLrP7+fAgC0aeGLAVKSFYIOrfw5J4uIbjpMqtyYNFGdSRU5UJDKB4ndwpHYrfZ5nIVlBuzMLcaOk8XYebIYB8/pceZiJc5cPIuv64YLQ/wV6BfdAgNiQnBLdAt0iwiCysfLmdUgInI4JlVuTBr+45wqakahAUrcGxeBe+MiAABlhhrsPnURO08WY0duMfacLkFxuRE/HczHTwfzAQA+XjJ0iwhCr6hg9K57xYSyN4uIPAuTKjdmSaqU7KkiJwpQekuPzwEAQ40J+8/qsfNkMXadLEZOXgmKyo3Ye0aHvWd0+DSzdshQ7esjJVl9ooLRKyoYIf4KZ1aFiOiGMKlyY5akyoc9VeRClN5e6BvdAn2jWwBDOkAIgTMXK5FzugR78kqw5/RF7D+nh66yGr/+eQG//nlBOja6pR96tQlGj9ZB6FH3IGm1n48Ta0NE1HhMqtwY51SRO5DJZIgK8UNUiB8e6BUJoPZ/CA5r9dhzukR6nbhQjlNFFThVVIFv956Tjm/TwhfdI4PQPVKNHq1r38MClRw6JCKXw6TKTQkhUG1Zp4pJFbkZhbccPdsEo2ebYIxLqN2mq6jG3jMl2Hu6BAfO6XHgvA6niyvrJsFX4scD+dLxoQEKdI9US8lW98ggtA3xg1zORIuInIdJlZuy9FIBTKrIM6j9fKzmZgG1idaB8zocPKfH/rM6HDinx/ELZSgsM+KXPy/gl8uGDv0UXogND0SX8EB0iQhEZ00gumiCOE+LiJoNkyo3ZZlPBfDuP/Jcaj8fDOwQioEdQqVtlUYTDmn1OHBOj4PndNh/Vo8j2lJUGE3Ye7q2p+tyrQKV6KIJROfwS4lWhzB/+Cn454+I7It/VdwUkyq6WfkqvHBL2xa4pW0LaVuNyYyTReU4rC3FkbqFSY9oS5FXXIELpQZcKDXgt6OFVudpHeyL9q380TEsAB3DaleU7xgWgJb+Cs7XIqImYVLlpizDfz5eMs4joZuet5ccHcMC0TEsEPf1vLS93FCDP/OtE60/80tRVG7E2ZJKnC2pvCrZUvv61CZarQLQIcxfSrjatPCDF/+tEVEDmFS5KS78SXR9/kpv9GnbAn0u69UCgIvlRhy/UIZjBbWv4xfKcOxCGc5crISushrZpy4i+9RFq2OU3nLEhPqjg5RwBaB9qD/ahfojQMk/pUTEpMptSWtUcZI6kc1a+CvQzz8E/dqFWG2vqjbhxIVyKeGyvJ8oLIehxiw98/BKoQFKtGvph+iW/ogJrX1v19If0aF+CFJxnS2imwWTKjdlYE8Vkd2pfLzQLTII3SKDrLabzAJnL1bi2IVSHC8or+3hulCGk4XlKCo3orDMgMIyA3Zd0bsF1D4HsV1Lv9okq6U/2oXW/tw2xA/Bfj6cv0XkQZhUualqLvxJ1Gy85DK0bemHti39cFcX6336qmrkFVUgt7Acp4rKcbKoQnq/UGpAcbkRxeVG7M4rueq8gUpvtG7hW7s4ags/RIX41r3X/sw7FIncC//FuilpThWTKiKnClL5oEdrNXq0Vl+1r8xQg1NFtSvFnywqx6nCCuQWleNkYTkKSg0oNdRcc0gRAFr6K9AmxA9RVyRebVr4IUKtgsrHy9HVIyIbMKlyU9Ijajj8R+SyApTedSu+X51wVVWbcOZiBU4XV+L0xQqcLrb+WV9Vg6JyY+3DqK9Ye8siNECByGBfRKp90bqFLyKDfdE6WFW7LdiXy0MQNTMmVW7K0lOlZE8VkVtS+XhJy0DUR1dZjdPFFVcnXhcrcfZiJSqrTSgsM6KwzIh9Z3T1nkPpLa9LsFSIVFuSrtoETKNWQROkgj/vXCSyG/5rclMc/iPybGpfH6ivMawohEBJRTXOllTinOWlq7L6XFBqgKHGjNzCcuQWll/zOoEqb0SoVQgPUiGiLtHSqH2hUSuhCapNvlpwQj1RozCpclNGTlQnumnJZDK08Feghb+i3qQLqP0fr3z9pUTr7MVKnNNV4mxJFc6VVEKrq0KZoQalVTUorSrDn/ll17yewltel2yppPewQCXCgureA5UIZ68XEZMqd2VZUsGHc6qIqB4Kb3ndXYR+14wprapGvr4KWp0B53WVyNdX4byuyuq9sMwIY40ZecUVyCuuaPCa/gqvS4lW3Xt4kBJhgZdtC1IiUOnNni/ySEyq3BRXVCeiGxWo8kGgyuea87oAwFBjQoHeAK2+Clpd7StfX4X8UgMK9FW4UGpAvr4K5UYTyo2m6w43AoDKR46wQBVaBigQGqBEaIASrQIUCA1USp9D6z4zASN3wqTKTXGdKiJqDkpvr+v2eAG1z1ksqEuwCuoSLst7vt6AgtLaz6VVNaiqblzPV+315ZeSLEvCFXjZzwFKtKr7rPbl3C9yLiZVbooT1YnIlfgrvRGj9EZMqH+DcZVGEwpKa3u4CssMuFBmRGHdz7WvuhXqSw0oN5pgqDFLD7++Hh8vGVr6K9EyQIEQ/8tefgqEBNS9+yvQMkCBFn4KBPsp+JBssismVW6KSyoQkTvyVXghuu6RPddTaTTVJV61SVZR+eUJmLF2e90+fVUNqk2idphSX9WosshkQAs/BVr4+aClvxIhdZP/W172HnLFiwuuUkOYVLkpLv5JRJ7OV9G4oUegdu5XUV0vV1G5EcVlRlysMEo/F1cYpUcGFZcboaushhCQPh+/0PA8MAs/hVddL5cPWvgpoPbzQQvLz7617y38faD2VUjbg3x92CN2k2BS5aY4/EdEdInS20taSb4xqk1mXKww4mJ5NYrKa5/ReLFuBfvia7xqzAIVRhMqjI0bjrSQyWofZ9TCzwdqP8U1kjAfKVlT+/ogSOWDQJU3vPk/zm6FSZWb4pIKRERN5+Mlr1vqQQXg2nc/WgghoK+qwcXy2h6wkopqlFTWJmUlFUaUVFbjYkXdzxXVUkyZoQZC1K6Qr6usBoquPzn/cv4KLwTVJVlqXx8E+XojSOVTt81b2hd02T5LUhag8mYPWTNziaRq6dKlWLRoEbRaLXr16oW3334bAwYMuGb82rVrMWfOHJw8eRKxsbH497//jeHDh0v7hRCYO3cuPvjgA5SUlOC2227De++9h9jYWCmmuLgYzz33HL777jvI5XI8/PDDeOuttxAQEAAA2LJlC9544w3s2LEDer0esbGxePHFFzF27FjH/SJswMU/iYiaj0wmq13l3tcH7XD9+WAW1SZzbQJmSbzKa99LKox1SZjl57pEraIapVXVKDeaAEBaquK8rnHzxK4UqKxLvK5KwqyTM7UUU7fP1wcBCm/ImZTZxOlJ1Zo1a5CSkoJly5YhPj4eb775JpKSknDkyBGEhYVdFb99+3aMGTMGaWlpuO+++7Bq1SokJydj9+7d6NGjBwBg4cKFWLJkCVauXImYmBjMmTMHSUlJOHjwIFQqFQBg7NixOH/+PDZu3Ijq6mpMmDABkydPxqpVq6Tr9OzZEzNmzEB4eDjWr1+PcePGQa1W47777mu+X9A1VHP4j4jI5fl4ydEqUIlWgUqbjqs2mVFaVQN9ZTX0VdXQV9bUvV/6rJN+rob+itjK6tqkrNRQg1JDjU3DlRYyWW1SpvarS7auSsZqP6vr6S0L8vWBv8LrplviQiaEEM4sQHx8PPr374933nkHAGA2mxEVFYXnnnsOL7/88lXxo0aNQnl5OdavXy9tu/XWW9G7d28sW7YMQghERkZi+vTpeOGFFwAAOp0O4eHhWLFiBUaPHo1Dhw6hW7du2LlzJ/r16wcASE9Px/Dhw3HmzBlERkbWW9YRI0YgPDwcH3/8caPqptfroVarodPpEBQUZNPv5Xqmrs7BN3vOYfaIrnhycHu7npuIiNybscaM0qrqusTr2smZrvLyfZdiLVNMboSXXIYApTcClN4IVNW+B6iu+KysHaYMVHkj8Kr9tfv8fLyavcesqe23U3uqjEYjsrOzMXPmTGmbXC5HYmIiMjMz6z0mMzMTKSkpVtuSkpKwbt06AEBubi60Wi0SExOl/Wq1GvHx8cjMzMTo0aORmZmJ4OBgKaECgMTERMjlcmRlZeHBBx+s99o6nQ5du3a9Zn0MBgMMBoP0Wa/XX7vyN4hLKhAR0bUovOVoGaBEywDbesgsqqpNKK1quDdMb0na6vaVSolaNapNAiazuDSX7AbIZECA4lLCdWVi9soDPeCrcI2lLpyaVBUWFsJkMiE8PNxqe3h4OA4fPlzvMVqttt54rVYr7bdsayjmyqFFb29vhISESDFX+vLLL7Fz5068//7716xPWloaXnnllWvutyfe/UdERI6i8vGCysfL5mFLoHZes6HGDF1lNUqralBmqEFZVQ3KDFd+rh2aLLtsW6mhNq6sqvZh3zVmASEuDWPW59UH4260unbj9DlV7mDz5s2YMGECPvjgA3Tv3v2acTNnzrTqRdPr9YiKinJImThRnYiIXJFMJpOSsvAbmPliSc5KrZKu6ktJmKEG5QaTS90F79SkKjQ0FF5eXsjPz7fanp+fD41GU+8xGo2mwXjLe35+PiIiIqxievfuLcUUFBRYnaOmpgbFxcVXXfeXX37B/fffjzfeeAPjxo1rsD5KpRJKZdO6Wm1lkB6o7BpdnkRERPZ0eXLWlB4zZ3BqeqdQKNC3b19kZGRI28xmMzIyMpCQkFDvMQkJCVbxALBx40YpPiYmBhqNxipGr9cjKytLiklISEBJSQmys7OlmE2bNsFsNiM+Pl7atmXLFowYMQL//ve/MXny5BuvsB0ZpXWqbq47K4iIiFyV04f/UlJSMH78ePTr1w8DBgzAm2++ifLyckyYMAEAMG7cOLRu3RppaWkAgKlTp2LIkCF47bXXMGLECKxevRq7du3C8uXLAdRmttOmTcP8+fMRGxsrLakQGRmJ5ORkAEDXrl0xbNgwTJo0CcuWLUN1dTWeffZZjB49Wrrzb/PmzbjvvvswdepUPPzww9JcK4VCgZCQkGb+LV2Nc6qIiIhci9OTqlGjRuHChQtITU2FVqtF7969kZ6eLk00z8vLg1x+KXEYOHAgVq1ahdmzZ2PWrFmIjY3FunXrpDWqAOCll15CeXk5Jk+ejJKSEgwaNAjp6enSGlUA8Pnnn+PZZ5/F0KFDpcU/lyxZIu1fuXIlKioqkJaWJiV0ADBkyBBs2bLFgb+RxqnmnCoiIiKX4vR1qjyZI9epGrJoM04VVeC/zySgb7Tze86IiIg8RVPbb3ZzuCkjJ6oTERG5FCZVbopzqoiIiFwLW2Q3xaSKiIjItbBFdlMGTlQnIiJyKWyR3ZAQgutUERERuRgmVW6o2nTphk0lJ6oTERG5BCZVbsiyRhXA4T8iIiJXwRbZDVmG/gAmVURERK6CLbIbMtb1VHnJZfCSc04VERGRK2BS5YYuLfzJr4+IiMhVsFV2QwauUUVERORy2Cq7IS78SURE5HrYKrshy5wqDv8RERG5DrbKbog9VURERK6HrbIbqmZPFRERkcthq+yG2FNFRETketgquyHe/UdEROR62Cq7IU5UJyIicj1sld0Qh/+IiIhcD1tlN8SkioiIyPWwVXZDxhoTAA7/ERERuRK2ym6o2iQAsKeKiIjIlbBVdkOcqE5EROR62Cq7IS6pQERE5HrYKrshTlQnIiJyPWyV3RCTKiIiItfDVtkNGU28+4+IiMjVsFV2Q+ypIiIicj1sld2QlFSxp4qIiMhlsFV2Q1ynioiIyPWwVXZDXFKBiIjI9bBVdkNc/JOIiMj1sFV2Q9Kz/9hTRURE5DLYKrsh3v1HRETketgquyFp+I9JFRERkctgq+yGuKQCERGR62Gr7IY4/EdEROR6XKJVXrp0Kdq1aweVSoX4+Hjs2LGjwfi1a9eiS5cuUKlUiIuLw4YNG6z2CyGQmpqKiIgI+Pr6IjExEUePHrWKKS4uxtixYxEUFITg4GBMnDgRZWVlVjH79u3D4MGDoVKpEBUVhYULF9qnwjdIWqeKPVVEREQuw+mt8po1a5CSkoK5c+di9+7d6NWrF5KSklBQUFBv/Pbt2zFmzBhMnDgROTk5SE5ORnJyMvbv3y/FLFy4EEuWLMGyZcuQlZUFf39/JCUloaqqSooZO3YsDhw4gI0bN2L9+vX49ddfMXnyZGm/Xq/HPffcg+joaGRnZ2PRokX4xz/+geXLlzvul9FIXKeKiIjIBQknGzBggJgyZYr02WQyicjISJGWllZv/KOPPipGjBhhtS0+Pl489dRTQgghzGaz0Gg0YtGiRdL+kpISoVQqxRdffCGEEOLgwYMCgNi5c6cU88MPPwiZTCbOnj0rhBDi3XffFS1atBAGg0GKmTFjhujcuXOj66bT6QQAodPpGn1MY8TNTRfRM9aLYwWldj0vERERNb39dmpXh9FoRHZ2NhITE6VtcrkciYmJyMzMrPeYzMxMq3gASEpKkuJzc3Oh1WqtYtRqNeLj46WYzMxMBAcHo1+/flJMYmIi5HI5srKypJjbb78dCoXC6jpHjhzBxYsX6y2bwWCAXq+3ejkCF/8kIiJyPU5tlQsLC2EymRAeHm61PTw8HFqttt5jtFptg/GW9+vFhIWFWe339vZGSEiIVUx957j8GldKS0uDWq2WXlFRUfVX/Ab5eMnh4yWDksN/RERELsPb2QXwJDNnzkRKSor0Wa/XOySx+uMfSXY/JxEREd0Yp3Z1hIaGwsvLC/n5+Vbb8/PzodFo6j1Go9E0GG95v17MlRPha2pqUFxcbBVT3zkuv8aVlEolgoKCrF5ERER0c3BqUqVQKNC3b19kZGRI28xmMzIyMpCQkFDvMQkJCVbxALBx40YpPiYmBhqNxipGr9cjKytLiklISEBJSQmys7OlmE2bNsFsNiM+Pl6K+fXXX1FdXW11nc6dO6NFixY3WHMiIiLyOA6aON9oq1evFkqlUqxYsUIcPHhQTJ48WQQHBwutViuEEOKxxx4TL7/8shS/bds24e3tLRYvXiwOHTok5s6dK3x8fMQff/whxSxYsEAEBweLb775Ruzbt0+MHDlSxMTEiMrKSilm2LBhok+fPiIrK0ts3bpVxMbGijFjxkj7S0pKRHh4uHjsscfE/v37xerVq4Wfn594//33G103R939R0RERI7T1Pbb6UmVEEK8/fbbom3btkKhUIgBAwaI33//Xdo3ZMgQMX78eKv4L7/8UnTq1EkoFArRvXt38f3331vtN5vNYs6cOSI8PFwolUoxdOhQceTIEauYoqIiMWbMGBEQECCCgoLEhAkTRGmp9RIFe/fuFYMGDRJKpVK0bt1aLFiwwKZ6MakiIiJyP01tv2VCCOHcvjLPpdfroVarodPpOL+KiIjITTS1/eY9+URERER2wKSKiIiIyA6YVBERERHZAZMqIiIiIjtgUkVERERkB0yqiIiIiOyASRURERGRHTCpIiIiIrIDJlVEREREduDt7AJ4Msti9Xq93sklISIiosaytNu2PnSGSZUDlZaWAgCioqKcXBIiIiKyVWlpKdRqdaPj+ew/BzKbzTh37hwCAwMhk8nsdl69Xo+oqCicPn3aI58p6On1Azy/jp5eP8Dz68j6uT9Pr6Mj6yeEQGlpKSIjIyGXN36mFHuqHEgul6NNmzYOO39QUJBH/kOx8PT6AZ5fR0+vH+D5dWT93J+n19FR9bOlh8qCE9WJiIiI7IBJFREREZEdMKlyQ0qlEnPnzoVSqXR2URzC0+sHeH4dPb1+gOfXkfVzf55eR1esHyeqExEREdkBe6qIiIiI7IBJFREREZEdMKkiIiIisgMmVURERER2wKTKDS1duhTt2rWDSqVCfHw8duzY4ewiIS0tDf3790dgYCDCwsKQnJyMI0eOWMXccccdkMlkVq+nn37aKiYvLw8jRoyAn58fwsLC8OKLL6KmpsYqZsuWLbjlllugVCrRsWNHrFix4qry2Pt39I9//OOqsnfp0kXaX1VVhSlTpqBly5YICAjAww8/jPz8fLeoGwC0a9fuqvrJZDJMmTIFgHt+d7/++ivuv/9+REZGQiaTYd26dVb7hRBITU1FREQEfH19kZiYiKNHj1rFFBcXY+zYsQgKCkJwcDAmTpyIsrIyq5h9+/Zh8ODBUKlUiIqKwsKFC68qy9q1a9GlSxeoVCrExcVhw4YNNpfFlvpVV1djxowZiIuLg7+/PyIjIzFu3DicO3fO6hz1fe8LFixwifpdr44A8Pjjj19V/mHDhlnFuOt3CKDef5MymQyLFi2SYlz5O2xMu+BKfzsbU5brEuRWVq9eLRQKhfj444/FgQMHxKRJk0RwcLDIz893armSkpLEJ598Ivbv3y/27Nkjhg8fLtq2bSvKysqkmCFDhohJkyaJ8+fPSy+dTiftr6mpET169BCJiYkiJydHbNiwQYSGhoqZM2dKMSdOnBB+fn4iJSVFHDx4ULz99tvCy8tLpKenSzGO+B3NnTtXdO/e3arsFy5ckPY//fTTIioqSmRkZIhdu3aJW2+9VQwcONAt6iaEEAUFBVZ127hxowAgNm/eLIRwz+9uw4YN4u9//7v4+uuvBQDxv//9z2r/ggULhFqtFuvWrRN79+4VDzzwgIiJiRGVlZVSzLBhw0SvXr3E77//Ln777TfRsWNHMWbMGGm/TqcT4eHhYuzYsWL//v3iiy++EL6+vuL999+XYrZt2ya8vLzEwoULxcGDB8Xs2bOFj4+P+OOPP2wqiy31KykpEYmJiWLNmjXi8OHDIjMzUwwYMED07dvX6hzR0dFi3rx5Vt/r5f9mnVm/69VRCCHGjx8vhg0bZlX+4uJiqxh3/Q6FEFb1On/+vPj444+FTCYTx48fl2Jc+TtsTLvgSn87r1eWxmBS5WYGDBggpkyZIn02mUwiMjJSpKWlObFUVysoKBAAxC+//CJtGzJkiJg6deo1j9mwYYOQy+VCq9VK29577z0RFBQkDAaDEEKIl156SXTv3t3quFGjRomkpCTpsyN+R3PnzhW9evWqd19JSYnw8fERa9eulbYdOnRIABCZmZkuX7f6TJ06VXTo0EGYzWYhhHt/d0KIqxoss9ksNBqNWLRokbStpKREKJVK8cUXXwghhDh48KAAIHbu3CnF/PDDD0Imk4mzZ88KIYR49913RYsWLaQ6CiHEjBkzROfOnaXPjz76qBgxYoRVeeLj48VTTz3V6LLYWr/67NixQwAQp06dkrZFR0eLN95445rHuEr9hKi/juPHjxcjR4685jGe9h2OHDlS3HXXXVbb3Ok7vLJdcKW/nY0pS2Nw+M+NGI1GZGdnIzExUdoml8uRmJiIzMxMJ5bsajqdDgAQEhJitf3zzz9HaGgoevTogZkzZ6KiokLal5mZibi4OISHh0vbkpKSoNfrceDAASnm8vpbYiz1d+Tv6OjRo4iMjET79u0xduxY5OXlAQCys7NRXV1tdc0uXbqgbdu20jVdvW6XMxqN+Oyzz/DEE09YPQjcnb+7K+Xm5kKr1VpdS61WIz4+3uo7Cw4ORr9+/aSYxMREyOVyZGVlSTG33347FAqFVZ2OHDmCixcvNqrejSmLPeh0OshkMgQHB1ttX7BgAVq2bIk+ffpg0aJFVsMq7lC/LVu2ICwsDJ07d8YzzzyDoqIiq/J7yneYn5+P77//HhMnTrxqn7t8h1e2C670t7MxZWkMPlDZjRQWFsJkMln9xwUA4eHhOHz4sJNKdTWz2Yxp06bhtttuQ48ePaTtf/3rXxEdHY3IyEjs27cPM2bMwJEjR/D1118DALRabb11s+xrKEav16OyshIXL150yO8oPj4eK1asQOfOnXH+/Hm88sorGDx4MPbv3w+tVguFQnFVYxUeHn7dcrtC3a60bt06lJSU4PHHH5e2ufN3Vx9Lmeq71uXlDQsLs9rv7e2NkJAQq5iYmJirzmHZ16JFi2vW+/JzXK8sN6qqqgozZszAmDFjrB48+/zzz+OWW25BSEgItm/fjpkzZ+L8+fN4/fXX3aJ+w4YNw0MPPYSYmBgcP34cs2bNwr333ovMzEx4eXl51He4cuVKBAYG4qGHHrLa7i7fYX3tgiv97WxMWRqDSRXZ3ZQpU7B//35s3brVavvkyZOln+Pi4hAREYGhQ4fi+PHj6NChQ3MX0yb33nuv9HPPnj0RHx+P6OhofPnll/D19XViyezvo48+wr333ovIyEhpmzt/dze76upqPProoxBC4L333rPal5KSIv3cs2dPKBQKPPXUU0hLS3OpR39cy+jRo6Wf4+Li0LNnT3To0AFbtmzB0KFDnVgy+/v4448xduxYqFQqq+3u8h1eq13wNBz+cyOhoaHw8vK66m6E/Px8aDQaJ5XK2rPPPov169dj8+bNaNOmTYOx8fHxAIBjx44BADQaTb11s+xrKCYoKAi+vr7N9jsKDg5Gp06dcOzYMWg0GhiNRpSUlFzzmu5St1OnTuHnn3/Gk08+2WCcO393l5epoWtpNBoUFBRY7a+pqUFxcbFdvtfL91+vLE1lSahOnTqFjRs3WvVS1Sc+Ph41NTU4efJkg2W/vNzOrN+V2rdvj9DQUKv/Lt39OwSA3377DUeOHLnuv0vANb/Da7ULrvS3szFlaQwmVW5EoVCgb9++yMjIkLaZzWZkZGQgISHBiSWrvd322Wefxf/+9z9s2rTpqu7m+uzZswcAEBERAQBISEjAH3/8YfVH0NIQdOvWTYq5vP6WGEv9m+t3VFZWhuPHjyMiIgJ9+/aFj4+P1TWPHDmCvLw86ZruUrdPPvkEYWFhGDFiRINx7vzdAUBMTAw0Go3VtfR6PbKysqy+s5KSEmRnZ0sxmzZtgtlslpLKhIQE/Prrr6iurraqU+fOndGiRYtG1bsxZWkKS0J19OhR/Pzzz2jZsuV1j9mzZw/kcrk0ZObK9avPmTNnUFRUZPXfpTt/hxYfffQR+vbti169el031pW+w+u1C670t7MxZWmURk9pJ5ewevVqoVQqxYoVK8TBgwfF5MmTRXBwsNWdEc7wzDPPCLVaLbZs2WJ1a29FRYUQQohjx46JefPmiV27donc3FzxzTffiPbt24vbb79dOofl1tl77rlH7NmzR6Snp4tWrVrVe+vsiy++KA4dOiSWLl1a762z9v4dTZ8+XWzZskXk5uaKbdu2icTERBEaGioKCgqEELW34rZt21Zs2rRJ7Nq1SyQkJIiEhAS3qJuFyWQSbdu2FTNmzLDa7q7fXWlpqcjJyRE5OTkCgHj99ddFTk6OdPfbggULRHBwsPjmm2/Evn37xMiRI+tdUqFPnz4iKytLbN26VcTGxlrdjl9SUiLCw8PFY489Jvbv3y9Wr14t/Pz8rrpd3dvbWyxevFgcOnRIzJ07t97b1a9XFlvqZzQaxQMPPCDatGkj9uzZY/Vv0nLH1Pbt28Ubb7wh9uzZI44fPy4+++wz0apVKzFu3DiXqN/16lhaWipeeOEFkZmZKXJzc8XPP/8sbrnlFhEbGyuqqqrc/ju00Ol0ws/PT7z33ntXHe/q3+H12gUhXOtv5/XK0hhMqtzQ22+/Ldq2bSsUCoUYMGCA+P33351dJAGg3tcnn3wihBAiLy9P3H777SIkJEQolUrRsWNH8eKLL1qtdSSEECdPnhT33nuv8PX1FaGhoWL69OmiurraKmbz5s2id+/eQqFQiPbt20vXuJy9f0ejRo0SERERQqFQiNatW4tRo0aJY8eOSfsrKyvF//t//0+0aNFC+Pn5iQcffFCcP3/eLepm8eOPPwoA4siRI1bb3fW727x5c73/TY4fP14IUXub+Jw5c0R4eLhQKpVi6NChV9W9qKhIjBkzRgQEBIigoCAxYcIEUVpaahWzd+9eMWjQIKFUKkXr1q3FggULrirLl19+KTp16iQUCoXo3r27+P777632N6YsttQvNzf3mv8mLWuPZWdni/j4eKFWq4VKpRJdu3YV//rXv6wSEmfW73p1rKioEPfcc49o1aqV8PHxEdHR0WLSpElXJeDu+h1avP/++8LX11eUlJRcdbyrf4fXaxeEcK2/nY0py/XI6ipORERERDeAc6qIiIiI7IBJFREREZEdMKkiIiIisgMmVURERER2wKSKiIiIyA6YVBERERHZAZMqIiIiIjtgUkVERERkB0yqiIgAtGvXDm+++aazi0FEboxJFRG5FZlM1uDrH//4R5POu3PnTkyePPmGypabm4u//vWviIyMhEqlQps2bTBy5EgcPnwYAHDy5EnIZDLpgdRE5Fm8nV0AIiJbnD9/Xvp5zZo1SE1NxZEjR6RtAQEB0s9CCJhMJnh7X/9PXatWrW6oXNXV1bj77rvRuXNnfP3114iIiMCZM2fwww8/oKSk5IbOTUTugT1VRORWNBqN9FKr1ZDJZNLnw4cPIzAwED/88AP69u0LpVKJrVu34vjx4xg5ciTCw8MREBCA/v374+eff7Y675XDfzKZDB9++CEefPBB+Pn5ITY2Ft9+++01y3XgwAEcP34c7777Lm699VZER0fjtttuw/z583HrrbcCAGJiYgAAffr0gUwmwx133CEd/+GHH6Jr165QqVTo0qUL3n33XWmfpYdr9erVGDhwIFQqFXr06IFffvnFDr9RIrIXJlVE5HFefvllLFiwAIcOHULPnj1RVlaG4cOHIyMjAzk5ORg2bBjuv/9+5OXlNXieV155BY8++ij27duH4cOHY+zYsSguLq43tlWrVpDL5fjqq69gMpnqjdmxYwcA4Oeff8b58+fx9ddfAwA+//xzpKam4tVXX8WhQ4fwr3/9C3PmzMHKlSutjn/xxRcxffp05OTkICEhAffffz+Kiops/fUQkaMIIiI39cknnwi1Wi193rx5swAg1q1bd91ju3fvLt5++23pc3R0tHjjjTekzwDE7Nmzpc9lZWUCgPjhhx+uec533nlH+Pn5icDAQHHnnXeKefPmiePHj0v7c3NzBQCRk5NjdVyHDh3EqlWrrLb985//FAkJCVbHLViwQNpfXV0t2rRpI/79739ft65E1DzYU0VEHqdfv35Wn8vKyvDCCy+ga9euCA4ORkBAAA4dOnTdnqqePXtKP/v7+yMoKAgFBQXXjJ8yZQq0Wi0+//xzJCQkYO3atejevTs2btx4zWPKy8tx/PhxTJw4EQEBAdJr/vz5OH78uFVsQkKC9LO3tzf69euHQ4cONVgHImo+nKhORB7H39/f6vMLL7yAjRs3YvHixejYsSN8fX3xl7/8BUajscHz+Pj4WH2WyWQwm80NHhMYGIj7778f999/P+bPn4+kpCTMnz8fd999d73xZWVlAIAPPvgA8fHxVvu8vLwavBYRuRb2VBGRx9u2bRsef/xxPPjgg4iLi4NGo8HJkycdfl2ZTIYuXbqgvLwcAKBQKADAas5VeHg4IiMjceLECXTs2NHqZZnYbvH7779LP9fU1CA7Oxtdu3Z1eD2IqHHYU0VEHi82NhZff/017r//fshkMsyZM+e6PU622rNnD+bOnYvHHnsM3bp1g0KhwC+//IKPP/4YM2bMAACEhYXB19cX6enpaNOmDVQqFdRqNV555RU8//zzUKvVGDZsGAwGA3bt2oWLFy8iJSVFusbSpUsRGxuLrl274o033sDFixfxxBNP2LUeRNR0TKqIyOO9/vrreOKJJzBw4ECEhoZixowZ0Ov1dr1GmzZt0K5dO7zyyivSEgiWz3/7298A1M6DWrJkCebNm4fU1FQMHjwYW7ZswZNPPgk/Pz8sWrQIL774Ivz9/REXF4dp06ZZXWPBggVYsGAB9uzZg44dO+Lbb79FaGioXetBRE0nE0IIZxeCiIiu7eTJk4iJiUFOTg569+7t7OIQ0TVwThURERGRHTCpIiIiIrIDDv8RERER2QF7qoiIiIjsgEkVERERkR0wqSIiIiKyAyZVRERERHbApIqIiIjIDphUEREREdkBkyoiIiIiO2BSRURERGQH/x9J7OoaV4icwwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef6e81",
   "metadata": {},
   "source": [
    "## 2. ChatBot 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daca65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc4122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dce21",
   "metadata": {},
   "source": [
    "질문과 대답의 쌍으로 이루어진 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74f9f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8b0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a3acc",
   "metadata": {},
   "source": [
    "tokenizer말고 다른 방법인 학습기반의 tokenizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ac5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de0b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a9e0759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd3f59",
   "metadata": {},
   "source": [
    "Tensorflow의 SubwordTokenizer를 사용해서 subword들로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b51fc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc077057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "066b04d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2107872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f7847bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8195dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1cbbf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
    "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3201eea",
   "metadata": {},
   "source": [
    "정수 encoding된 단어들을 transformer에 넣기 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f2e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b0525f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e2e6f",
   "metadata": {},
   "source": [
    "크기가 전부 40으로 동일한 input data가 완성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0feb3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "948b0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 0번 샘플을 임의로 출력\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0ed97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d9e4139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1741425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8180, 256)\n",
      "(1, 8180, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef0a37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d060aeba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 130s 643ms/step - loss: 1.4511 - accuracy: 0.0298\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 123s 666ms/step - loss: 1.1775 - accuracy: 0.0495\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 122s 660ms/step - loss: 1.0019 - accuracy: 0.0507\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 123s 667ms/step - loss: 0.9284 - accuracy: 0.0542\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 124s 672ms/step - loss: 0.8720 - accuracy: 0.0572\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 125s 674ms/step - loss: 0.8139 - accuracy: 0.0614\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 126s 679ms/step - loss: 0.7488 - accuracy: 0.0671\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 126s 684ms/step - loss: 0.6762 - accuracy: 0.0750\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 126s 684ms/step - loss: 0.5972 - accuracy: 0.0835\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 126s 683ms/step - loss: 0.5148 - accuracy: 0.0930\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 126s 680ms/step - loss: 0.4314 - accuracy: 0.1031\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 126s 682ms/step - loss: 0.3508 - accuracy: 0.1139\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 127s 686ms/step - loss: 0.2755 - accuracy: 0.1254\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 127s 684ms/step - loss: 0.2088 - accuracy: 0.1357\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 127s 685ms/step - loss: 0.1540 - accuracy: 0.1450\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 127s 685ms/step - loss: 0.1108 - accuracy: 0.1528\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 127s 686ms/step - loss: 0.0803 - accuracy: 0.1586\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 126s 683ms/step - loss: 0.0610 - accuracy: 0.1621\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 126s 680ms/step - loss: 0.0511 - accuracy: 0.1636\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 126s 681ms/step - loss: 0.0454 - accuracy: 0.1645\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 128s 692ms/step - loss: 0.0422 - accuracy: 0.1649\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 127s 687ms/step - loss: 0.0394 - accuracy: 0.1656\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 124s 671ms/step - loss: 0.0366 - accuracy: 0.1661\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 119s 641ms/step - loss: 0.0313 - accuracy: 0.1673\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 118s 636ms/step - loss: 0.0277 - accuracy: 0.1682\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 118s 640ms/step - loss: 0.0247 - accuracy: 0.1688\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 118s 638ms/step - loss: 0.0215 - accuracy: 0.1699\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 118s 639ms/step - loss: 0.0202 - accuracy: 0.1701\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 118s 639ms/step - loss: 0.0180 - accuracy: 0.1706\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 118s 640ms/step - loss: 0.0164 - accuracy: 0.1710\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 118s 638ms/step - loss: 0.0151 - accuracy: 0.1714\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 119s 643ms/step - loss: 0.0135 - accuracy: 0.1718\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 118s 640ms/step - loss: 0.0127 - accuracy: 0.1721\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 118s 637ms/step - loss: 0.0122 - accuracy: 0.1721\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 119s 641ms/step - loss: 0.0116 - accuracy: 0.1723\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 120s 649ms/step - loss: 0.0107 - accuracy: 0.1726\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 120s 648ms/step - loss: 0.0099 - accuracy: 0.1726\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 120s 647ms/step - loss: 0.0096 - accuracy: 0.1727\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 119s 643ms/step - loss: 0.0087 - accuracy: 0.1730\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 119s 642ms/step - loss: 0.0090 - accuracy: 0.1729\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 118s 640ms/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 118s 637ms/step - loss: 0.0078 - accuracy: 0.1732\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 120s 649ms/step - loss: 0.0074 - accuracy: 0.1734\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 121s 652ms/step - loss: 0.0071 - accuracy: 0.1734\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 117s 633ms/step - loss: 0.0068 - accuracy: 0.1735\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 117s 634ms/step - loss: 0.0065 - accuracy: 0.1736\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 118s 637ms/step - loss: 0.0063 - accuracy: 0.1736\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 118s 637ms/step - loss: 0.0059 - accuracy: 0.1737\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 117s 634ms/step - loss: 0.0059 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 120s 647ms/step - loss: 0.0055 - accuracy: 0.1738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d82c82c7f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047810ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점 사이에 공백 추가.\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46cc279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    # 입력 문장에 대한 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 현재 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "        # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "621cfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "\n",
    "    # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "    # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1593019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너 뭐해?\n",
      "Output: 마음을 비우세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너 뭐해?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8fd27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 그게 무슨 말이야?\n",
      "Output: 외롭다고 당신의 감정을 솔직하게 말해보세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"그게 무슨 말이야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "534d434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 내가 외롭다는 거야?\n",
      "Output: 제가 있잖아요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"내가 외롭다는 거야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "beb5b70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 그러게\n",
      "Output: 조금 더 일찍  ?\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"그러게\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7ad299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 조금 더 일찍 뭐?\n",
      "Output: 오늘 일찍 주무세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"조금 더 일찍 뭐?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5679f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 대화가 이상하다?\n",
      "Output: 그런 일이 많이 생기죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"대화가 이상하다?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b07e0069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 그렇긴 하지\n",
      "Output: 그래도 상관없어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"그렇긴 하지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c1fafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오늘 운영체제 공부했어.\n",
      "Output: 우선 꾸준히 연락하고 잘해줘보세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"오늘 운영체제 공부했어.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c815e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 운영체제는 사람이 아니야\n",
      "Output: 혼자 힘들어하지 마세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"운영체제는 사람이 아니야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6e599aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ???\n",
      "Output: 잘하고 있을 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"???\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
